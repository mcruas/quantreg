---
title: "Application of quantile regression for Metheorological Time Series modelling" 
author: "Marcelo" 
date: "November 12, 2016" 
output: 
  beamer_presentation: 
    fonttheme: professionalfonts
    toc: yes
---


# Introduction

## Introduction

* Wind Firm Energy Certificate (FEC) (Porrua, 2010) estimation imposes several 
challenges:
    + It is a quantile function of an aleatory quantity, named here on wind 
capacity factor (WP). Due to its non-dispachable profile, accurate scenario 
generation models could reproduce a fairly dependence structure in order to the 
estimation of FEC.
    + Second, as it is a quantile functions, the more close to the extremes of the 
interval, the more sensitive to sampling error.

## Introduction

- The main frameworks we investigate are parametric linear models and a 
non-parametric regression: both for quantile regressions.

- In all approaches we use only time series lags as the regression covariates.

- To study our methods performance, we use the mean power monthly data of 
Icaraizinho, a wind farm located in the Brazilian northeast.

## The Icaraizinho dataset

- The Icaraizinho dataset consists of monthly observations from 1981 to 2011 of 
mean power measured in Megawatts.

![The Icaraizinho dataset](Documento Regressao 
Quantilica/Figuras/Icaraizinho/icaraizinho-mensal.pdf)


## Quantile Regression

A Quantile Regression for the $\alpha$-quantile is the solution of the following
optimization problem: $$ 
\min_{q}\sum_{t=1}^{n}\alpha|y_{t}-q(x_t)|^{+}+(1-\alpha)|y_{t}-q(x_t)|^{-}, 
\label{eq:linear-model} $$
where $q(x_t)$ is the estimated quantile value at a 
given time $t$ and $|x|^+=\max\{0,x\}$ and $|x|^-=-\min\{0,x\}$. To model this 
problem as a Linear Programming problem, thus being able to use a modern solver 
to fit our model,  we can create variables $\varepsilon^+_t$ e $\varepsilon^-_t$
to represent $|y-q(x_t)|^+$ and $|y-q(x_t)|^-$, respectively. So we have: 
\[ 
\begin{aligned}\min_{q,\varepsilon_{t}^{+}, \varepsilon_{t}^{-}} & 
\sum_{t=1}^{n}\left(\lambda\varepsilon_{t}^{+}+(1-\lambda)\varepsilon_{t}^{-}\right)
& \\ \mbox{s.t. } & \varepsilon_{t}^{+}-\varepsilon_{t}^{-}=y_{t}-q(x_{t}), & 
\qquad\forall t \in \{1,\dots,n\},\\ & \varepsilon_t^+,\varepsilon_t^- \geq 0, &
\qquad \forall t \in \{1,\dots,n\}. \end{aligned} \label{eq:qar-general} 
\]


## Relationship between $y_t$ and some lags

\begin{figure} \centering \begin{minipage}[t]{0.45\linewidth} \centering 
\begin{minipage}[t]{\linewidth} \centering 
\includegraphics[width=\textwidth]{Documento Regressao 
Quantilica/Figuras/Icaraizinho/icaraizinho-1-lag.pdf} \end{minipage} 
\begin{minipage}[b]{\linewidth} \centering 
\includegraphics[width=\textwidth]{Documento Regressao 
Quantilica/Figuras/Icaraizinho/icaraizinho-4-lag.pdf} \end{minipage} 
\end{minipage} \begin{minipage}[t]{0.45\linewidth} \centering 
\begin{minipage}[t]{\linewidth} \centering 
\includegraphics[width=\textwidth]{Documento Regressao 
Quantilica/Figuras/Icaraizinho/icaraizinho-11-lag.pdf} \end{minipage} 
\begin{minipage}[b]{\linewidth} \centering 
\includegraphics[width=\textwidth]{Documento Regressao 
Quantilica/Figuras/Icaraizinho/icaraizinho-12-lag.pdf} \end{minipage} 
\end{minipage} \caption{Relationship between $y_t$ and some chosen lags.} 
\label{lags-icaraizinho} \end{figure}

## Relationship between $y_t$ and some lags


\begin{columns}
\column{0.5\textwidth}
\centering
\includegraphics[width=\textwidth]{Documento Regressao Quantilica/Figuras/npqar/icaraizinho-crossing-10}

$\lambda = 10$

\column{0.5\textwidth}
\centering
\includegraphics[width=\textwidth]{Documento Regressao Quantilica/Figuras/npqar/icaraizinho-crossing-200}

Degenerated case with $\lambda = 200$


\end{columns}

# Linear Models for the Quantile Autoregression

## Best subset selection with Mixed Integer Programming

- We investigate the usage of Mixed Integer Programming to select which 
variables are included in the model, up to a limit of inclusions imposed 
\textit{a priori}. The optimization problem is described below:

\begin{eqnarray*} \min_{\beta_{0},\beta, 
z,\varepsilon_{t}^{+},\varepsilon_{t}^{-}} & 
\sum_{t=1}^{n}\left(\alpha\varepsilon_{t}^{+}+(1-\alpha)\varepsilon_{t}^{-}\right)
\\ \mbox{s.t } & 
\varepsilon_{t}^{+}-\varepsilon_{t}^{-}=y_{t}-\beta_{0}-\sum_{p=1}^{P}\beta_{p}x_{t,p},&
\quad\forall t\in\{1,\dots,n\}, \label{linear1}\\ & 
\varepsilon_{t}^{+},\varepsilon_{t}^{-}\geq0,&\quad\forall t \in \{1,\dots,n\}, 
\label{linear2}\\ & - M_U z_p \leq \beta_p \leq M_U z_p,&\quad\forall 
p\in\{1,\dots,P\}, \label{linear3}\\ & \sum_{p=1}^P z_p \leq K, 
\label{linear4}\\ & z_p \in \{0,1\},&\quad\forall p\in\{1,\dots,P\}. 
\label{eq:linear5} \end{eqnarray*}


## Best subset selection with Mixed Integer Programming

\begin{figure} \centering \includegraphics[width=0.7\linewidth]{Documento 
Regressao Quantilica/Figuras/npqar/icaraizinho-crossing-200} \caption{Linear 
Quantile Regression when only $y_{t-1}$ is used} 
\label{fig:icaraizinho-crossing-200} \end{figure}


## Best subset selection with Mixed Integer Programming

\begin{table}[ht] \centering \begin{tabular}{rrrrrrrrrrrrr} \hline & K=1 & K=2 &
K=3 & K=4 & K=5 & K=6 & K=7 & K=8 \\ \hline $\beta_{0}$ & -15.33 & 9.38 & 1.48 &
1.34 & 8.72 & -1.68 & 4.94 & 0.65 \\ $\beta_{1}$ & -0.00 & 0.79 & 0.66 & 0.58 & 
0.46 & 0.40 & 0.48 & 0.46  \\ $\beta_{2}$ & -0.00 & -0.00 & -0.00 & -0.00 & 
-0.00 & 0.33 & -0.00 & -0.00 \\ $\beta_{3}$ & -0.00 & -0.00 & -0.00 & -0.00 & 
-0.00 & -0.00 & -0.00 & 0.20  \\ $\beta_{4}$ & -0.00 & -0.47 & -0.28 & -0.27 & 
-0.29 & -0.35 & -0.31 & -0.40 \\ $\beta_{5}$ & -0.00 & -0.00 & -0.00 & -0.00 & 
-0.00 & -0.00 & -0.00 & -0.00 \\ $\beta_{6}$ & -0.00 & -0.00 & -0.00 & -0.00 & 
-0.00 & -0.00 & 0.11 & 0.08  \\ $\beta_{7}$ & -0.00 & -0.00 & -0.00 & -0.00 & 
-0.00 & -0.00 & -0.00 & -0.00 \\ $\beta_{8}$ & -0.00 & -0.00 & -0.00 & -0.00 & 
-0.15 & -0.00 & -0.31 & -0.26 \\ $\beta_{9}$ & -0.00 & -0.00 & -0.00 & -0.00 & 
-0.00 & 0.14 & 0.16 & 0.20 \\ $\beta_{10}$ & -0.00 & -0.00 & -0.00 & -0.00 & 
-0.00 & -0.00 & -0.00 & -0.00 \\ $\beta_{11}$ & -0.00 & -0.00 & 0.26 & 0.17 & 
0.21 & 0.08 & 0.16 & 0.19  \\ $\beta_{12}$ & 1.17 & -0.00 & -0.00 & 0.18 & 0.15 
& 0.19 & 0.22 & 0.20  \\ \hline \end{tabular} \caption{Coefficients for quantile
$\alpha = 0.05$} \end{table}


## Best subset selection with a $\ell_1$ penalty

- Another way of doing regularization is including the $\ell_1$-norm of the 
coefficients on the objective function.

- By lowering the penalty we impose on the $\ell_1$-norm, more variables are 
being added to the model.

- This is the same strategy of the LASSO, and its usage for the quantile 
regression is discussed in Li and Zhu (2012).



- The proposed optimization problem to be solved is:

\[ 
\min_{\beta_{0},\beta}\sum_{t=1}^{n}\alpha|y_{t}-q(x_t)|^{+}+(1-\alpha)|y_{t}-q(x_t)|^{-}+\lambda\|\beta\|_{1}
\] \[ q(x_t)=\beta_{0}-\sum_{p=1}^{P}\beta_{p}x_{t,p}, \]


## Best subset selection with a $\ell_1$ penalty

- In order to represent the above problem to be solved with linear programming 
solver, we restructure the problem as below:
\[
\begin{aligned} \beta_\lambda^{*LASSO} = 
argmin_{\beta_{0},\beta,\varepsilon_{t}^{+},\varepsilon_{t}^{-}} & 
\sum_{i=1}^{n}\left(\alpha\varepsilon_{t}^{+}+(1-\alpha)\varepsilon_{t}^{-}\right)+\lambda\sum_{p=1}^{P}\xi_p\\
& \varepsilon_{t}^{+},\varepsilon_{t}^{-}\geq0,\qquad\forall t \in 
\{1,\dots,n\},\\ & \varepsilon_{t}^{+},\varepsilon_{t}^{-}\geq0,\qquad\forall t 
\in \{1,\dots,n\},\\ & \xi_{p}\geq\beta_{p},\qquad\forall p\in\{1,\dots,P\}, \\ 
& \xi_{p}\geq-\beta_{p},\qquad\forall p\in\{1,\dots,P\}, \\ \end{aligned}
\]

## Best subset selection with a $\ell_1$ penalty

- For low values of $\lambda$, the penalty is small and thus we have a model 
where all coefficients have a nonzero value. - When $\lambda$ is increased, the 
coefficients shrink towards zero (as an extreme case we have a constant model) -
The linear coefficient $\beta_0$ is not penalized. - We make this experiment For
the same quantiles values of $\alpha$ we experimented on the previous section 
($\alpha \in \{0.05, 0.1, 0.5, 0.9, 0.95\}$).

## Best subset selection with a $\ell_1$ penalty

\begin{figure} \centering \begin{minipage}[t]{0.4\linewidth} \centering 
\begin{minipage}[t]{\linewidth} \centering 
\includegraphics[width=\textwidth]{Documento Regressao 
Quantilica/Figuras/selecao-lasso/par-sellasso-005.pdf} \end{minipage} 
\begin{minipage}[b]{\linewidth} \centering 
\includegraphics[width=\textwidth]{Documento Regressao 
Quantilica/Figuras/selecao-lasso/par-sellasso-01.pdf} \end{minipage} 
\begin{minipage}[b]{\linewidth} \centering 
\includegraphics[width=\textwidth]{Documento Regressao 
Quantilica/Figuras/selecao-lasso/par-sellasso-05.pdf} \end{minipage} 
\end{minipage} \begin{minipage}[t]{0.4\linewidth} \centering 
\begin{minipage}[b]{\linewidth} \centering 
\includegraphics[width=\textwidth]{Documento Regressao 
Quantilica/Figuras/selecao-lasso/par-sellasso-09.pdf} \end{minipage} 
\begin{minipage}[b]{\linewidth} \centering 
\includegraphics[width=\textwidth]{Documento Regressao 
Quantilica/Figuras/selecao-lasso/par-sellasso-095.pdf} \label{fig:npqar-cross} 
\end{minipage} \end{minipage} \caption{Coefficients path for a few different 
values of $\alpha$-quantiles. $\lambda$ is presented in a $\log_{10}$ scale, to 
make visualization easier.} \end{figure}


## Simulation Study

- We propose simulating an AR(1) model \begin{equation} y_t = \phi_0 +  \phi 
y_{t-1} + \varepsilon_t,\qquad \varepsilon_t \sim N(0, \sigma_\varepsilon^2), 
\label{eq:sim-true-model} \end{equation} and test two approaches to predict the 
one-step ahead quantile. 
- On the first one, we consider known this process true
model, thus estimating values for $\hat{\phi}_0$, $\hat{\phi}$ and 
$\hat{\sigma}_\epsilon^2$. 
- On the second approach, we use the quantile 
regression to make a direct estimation of the quantiles.


## Simulation Study


## Simulation Study

# Quantile Autoregression with a nonparametric approach

## Formulation

Let $\{\tilde{y}_t \}_{t=1}^n$ be the sequence of observations in time $t$. Now, let $\tilde{x}_t$ be the $p-$lagged time series of $\tilde{y}_t$, such that $\tilde{x}_t = L^p(\tilde{y}_t)$, where $L$ is the lag operator. Matching each observation $\tilde{y}_t$ with its $p-$lagged correspondent $\tilde{x}_t$ will produce $n-p$ pairs $\{(\tilde{y}_t,\tilde{x}_t)\}_{t=p+1}^n$ (note that the first $p$ observations of $y_t$ must be discarded). When we order the observation of $x$ in such way that they are in growing order
$$\tilde{x}^{(p+1)} \leq \tilde{x}^{(p+2)} \leq \dots \leq \tilde{x}^{(n)},$$ 
we can then define $\{x_i\}_{i=1}^{n-p} = \{\tilde{x}^{(t)} \}_{t=p+1}^{n}$ and $\{y_i\}_{i=1}^{n-p} = \{\tilde{y}^{(t)} \}_{t=p+1}^{n}$ and $T = \{2,\dots, n-p-1\}$. As we need the second difference of $q_i$, $I$ has to be shortened by two elements.

## The optimization problem

Our optimization model to estimate the nonparametric quantile is as follows:
\[
\begin{split}
\mathcal{Q}_{y_t|y_{t-1}}^\alpha(t) =\underset{q_{t}}{\arg\min}\sum_{t\in T}\left(|y_{t}-q_{t}|^{+}\alpha + |y_{t}-q_{t}|^{-}(1-\alpha)\right) \\ +\lambda  \sum_{t\in T}|D_{x_t}^{2}q_{t}|,
\end{split}
\]
where $D^2 q_t$ is the second derivative of the $q_t$ function, calculated as follows:
\[
D_{x_t}^{2}q_{t}=\left(\frac{q_{t+1}-q_{t}}{x_{t+1}-x_{t}}\right)-\left(\frac{q_t-q_{t-1}}{x_{t}-x_{t-1}}\right).
\]


## The optimization problem

The full model can be rewritten as a LP problem as bellow:


\begin{eqnarray*}
\min_{q_{t}} & \sum_{t=1}^{n}\left(\alpha\delta_{t}^{+}+(1-\alpha)\delta_{t}^{-}\right)+\lambda\sum_{t=1}^{n}\xi_{t}\\
s.t. & \delta_{t}^{+}-\delta_{t}^{-}=y_{t}-q_{t}, & \qquad\forall t\in\{3,\dots,n-1\},\\
 & D_{t}=\left(\frac{q_{t+1}-q_{t}}{x_{t+1}-x_{t}}\right)-\left(\frac{q_{t}-q_{t-1}}{x_{t}-x_{t-1}}\right) & \qquad\forall t\in\{3,\dots,n-1\},\\
 & \xi_{t}\geq D_{t}, & \qquad\forall t\in\{3,\dots,n-1\},\\
 & \xi_{t}\geq-D_{t}, & \qquad\forall t\in\{3,\dots,n-1\},\\
 & \delta_{t}^{+},\delta_{t}^{-},\xi_{t}\geq0, & \qquad\forall t\in\{3,\dots,n-1\}.
\end{eqnarray*}


## Tunning

- The output of our optimization problem is a sequence of ordered points $\{(x_t, q_t)\}_{t \in T}$. The next step is to interpolate these points in order to provide an estimation for any other value of $x$. To address this issue, we propose using a B-splines interpolation, that will be developed in another study.

- The quantile estimation is done for different values of $\lambda$. By using different levels of penalization on the second difference, the estimation can be more or less adaptive to the fluctuation. It is important to notice that the usage of the $\ell_1$-norm as penalty leads to a piecewise linear solution $q_t$.

- Quantile estimation for a few different values of $\lambda$ are shown on the next slides. 


## Quantile estimation for different values of $\lambda$

\begin{columns}
\column{0.5\textwidth}
\centering

\includegraphics[width=\textwidth]{Documento Regressao Quantilica/Figuras/npqar/icaraizinho-crossing-01}

Overfitting with $\lambda = 0.1$


\column{0.5\textwidth}
\centering

\includegraphics[width=\textwidth]{Documento Regressao Quantilica/Figuras/npqar/icaraizinho-crossing-03}

$\lambda = 0.3$

\end{columns}



## Quantile estimation for different values of $\lambda$

\begin{columns}
\column{0.5\textwidth}
\centering

\includegraphics[width=\textwidth]{Documento Regressao Quantilica/Figuras/npqar/icaraizinho-crossing-1}

$\lambda = 1$


\column{0.5\textwidth}
\centering

\includegraphics[width=\textwidth]{Documento Regressao Quantilica/Figuras/npqar/icaraizinho-crossing-3}

$\lambda = 3$

\end{columns}


## Quantile estimation for different values of $\lambda$


\begin{columns}
\column{0.5\textwidth}
\centering
\includegraphics[width=\textwidth]{Documento Regressao Quantilica/Figuras/npqar/icaraizinho-crossing-10}

$\lambda = 10$

\column{0.5\textwidth}
\centering
\includegraphics[width=\textwidth]{Documento Regressao Quantilica/Figuras/npqar/icaraizinho-crossing-200}

Degenerated case with $\lambda = 200$


\end{columns}



## Open issues about the nonparametric quantile autoregression

- The first issue is **how to select an appropriate value for $\lambda$**. A simple way is to do it by inspection, which means to test many different values and pick the one that suits best our needs by looking at them. The other alternative is to use a metric to which we can select the best tune. We can achieve this by using a cross-validation method, for example.

- The other issue occurs when **we try to add more than one lag to the analysis at the same time**. This happens because the problem solution is a set of points that we need to interpolate. This multivariate interpolation, however, is not easily solved, in the sense that we can either choose using a very naive estimator such as the K-nearest neighbors or just find another method that is not yet adopted for a wide range of applications.


# Next steps


## Testing methods with high-frequency data

- All methods already discussed applied to high frequency data on different locations


## Local Quantile Regression

- Based on Bremmes (2004). Being the estimation of the $\theta$ quantile 
$q_\theta():$ \[ q_{\theta}(x; \alpha_0,\alpha)=\alpha_0 + \alpha^T x \] we 
define the local quantile regression by solving the following optimization 
problem: \[ argmin_{(\alpha_0, \alpha)} \sum_{i=1}^n \rho_\theta (e_{\rho,i} - 
q_\theta( x_i - x;\alpha_0,\alpha)) w \left(  \frac{\|x_i - x \|_2 
}{h_\lambda(x)}  \right) \] where the loss function is defined by \[ 
\rho_\theta(u) = \begin{cases} u\theta & \text{if } u\geq 0\\ u(\theta-1) & 
\text{otherwise} \end{cases} \] and the weight function \[ w(u) = \begin{cases} 
(1-u^3)^3 & \text{if } u \in [0,1)\\ 0 & \text{otherwise} \end{cases} \]

## Generating Scenarios of Wind Power Prediction

- Following recommendation of Pinson and Madsen (2009). This method is employed
for short term monte carlon simulation.

- 1. One must have a different model for each horizon $k \in \{ 1, \dots, K \}$. 
Residuals $\boldsymbol{X}$ come from a multivariate Gaussian distribution $\boldsymbol{X} \sim N(\mu_0,\Sigma_{t-K})$. As we want to generate $d$ different
scenarios, we have to take $d$ samples.  

- 2. By applying the inverse probit function $\Phi$ to each component of $\boldsymbol{X}^{(i)}$, we obtain the random variable $Y_k^{(t)} = \Phi(\boldsymbol{X}^{(i)}_k), \forall k,i$. 

- 3. The predicted value of for time $t+k$ for the *i*th scenario is given by:
$$\hat{p}^{(i)}_{t+k|t}=\hat{F}^{-1}_{t+k|t}(Y^{(i)}_k),\quad \forall k,i, $$
where $\hat{F}$ is the distribution function. 

- Quantile regression is used to approximate distribution function $F$ and using splines. 


## Multiple states defining multiple models

-  Explore the possibility of having different models for different states of climate conditions.

- One approach is using unsupervised classification techniques, such as support vector machines